{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import secrets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from cvxopt import matrix\n",
    "from cvxopt import solvers\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "solvers.options['show_progress'] = False\n",
    "# solvers.options['glpk'] = dict(msg_lev='GLP_MSG_OFF')\n",
    "sns.set_context(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path().resolve().parent / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "# secrets.randbits(128) # 208905213533139122735706682150229709525\n",
    "rng = np.random.default_rng(208905213533139122735706682150229709525)\n",
    "indices_train = rng.choice(5000, 500, replace=False)\n",
    "indices_test = rng.choice(800, 500, replace=False)\n",
    "flag_full_dataset = False  # If it is True it will use full train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list = []  # Auxiliary list of train datasets\n",
    "# for f in data_path.glob(\"train*.txt\"):\n",
    "#     # Sample or full dataset\n",
    "#     raw_data = np.loadtxt(f) if flag_full_dataset else np.loadtxt(f)[indices_train, :]\n",
    "#     target = raw_data[:, [0]]  # Target values, i.e. digit\n",
    "#     features = raw_data[:, 1:] / 255\n",
    "#     train_list.append(np.hstack((target, features)))  # Add to the temp list\n",
    "# train_data = np.vstack(train_list)  # Concatenate train datasets\n",
    "# train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Similar to train dataset\n",
    "# test_list = []\n",
    "# for f in data_path.glob(\"test*.txt\"):\n",
    "#     raw_data = np.loadtxt(f) if flag_full_dataset else np.loadtxt(f)[indices_test, :]\n",
    "#     target = raw_data[:, [0]]\n",
    "#     features = raw_data[:, 1:] / 255\n",
    "#     test_list.append(np.hstack((target, features)))\n",
    "# test_data = np.vstack(test_list)\n",
    "# test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split datasets into features matrices and target vectors\n",
    "# X_train = train_data[:, 1:]\n",
    "# y_train = train_data[:, 0].astype(int)\n",
    "# X_test = test_data[:, 1:]\n",
    "# y_test = test_data[:, 0].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(labels, n_train_label, n_test_label, rng):\n",
    "    train_list = []  # Auxiliary list of train datasets\n",
    "    for f_train in data_path.glob(\"train*.txt\"):\n",
    "        if f_train.stem.removeprefix(\"train\") not in map(str, labels):\n",
    "            continue\n",
    "        raw_train = np.loadtxt(f_train)\n",
    "        if n_train_label is not None:\n",
    "            indices_train = rng.choice(raw_train.shape[0], n_train_label, replace=False)\n",
    "            raw_train = raw_train[indices_train, :]\n",
    "        target_train = raw_train[:, [0]]  # Target values, i.e. digit\n",
    "        features_train = raw_train[:, 1:] / 255\n",
    "        train_list.append(np.hstack((target_train, features_train)))\n",
    "    train_data = np.vstack(train_list)  # Concatenate train datasets\n",
    "\n",
    "    test_list = []\n",
    "    for f_test in data_path.glob(\"test*.txt\"):\n",
    "        if f_test.stem.removeprefix(\"test\") not in map(str, labels):\n",
    "            continue\n",
    "        raw_test = np.loadtxt(f_test)\n",
    "        if n_test_label is not None:\n",
    "            indices_test = rng.choice(raw_test.shape[0], n_test_label, replace=False)\n",
    "            raw_test = raw_test[indices_test, :]\n",
    "        target_test = raw_test[:, [0]]\n",
    "        features_test = raw_test[:, 1:] / 255\n",
    "        test_list.append(np.hstack((target_test, features_test)))\n",
    "    test_data = np.vstack(test_list)\n",
    "    X_train = train_data[:, 1:]\n",
    "    y_train = train_data[:, 0].astype(int)\n",
    "    X_test = test_data[:, 1:]\n",
    "    y_test = test_data[:, 0].astype(int)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radial_basis(X1, X2, gamma):\n",
    "    K = np.exp(-gamma * euclidean_distances(X1, X2,squared=True))\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([3, 6])\n",
    "n_train_label = 500\n",
    "n_test_label = 500\n",
    "X_train, y_train, X_test, y_test = get_data(labels, n_train_label, n_test_label, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_i \\in {-1, 1}\n",
    "min_label = np.min(labels)\n",
    "y_train_bin = np.where(y_train == min_label, -1, 1)\n",
    "y_test_bin = np.where(y_test == min_label, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_train = y_train.size\n",
    "# n_test = y_test.size\n",
    "# K_train = radial_basis(X_train, X_train, gamma)\n",
    "# M = matrix(np.outer(y_train_bin, y_train_bin) * K_train)\n",
    "# e = matrix(np.ones(shape=(n_train, 1), dtype=float))\n",
    "# G = matrix(np.identity(n=n_train, dtype=float))\n",
    "# h = matrix(C * e)\n",
    "# A = matrix(y_train_bin.reshape(1, -1).astype(float))\n",
    "# b = matrix(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sol = solvers.qp(M, e, G, h, A, b)\n",
    "# alpha = np.array(sol[\"x\"]).flatten()\n",
    "# I = np.argwhere(alpha > 0).flatten()\n",
    "# alpha_b_idx = np.argwhere((0 < alpha) & (alpha < C)).flatten()\n",
    "# b = np.sum(y_train_bin[I] *  alpha[I] * K_train[I, alpha_b_idx[0]])\n",
    "# K_test = radial_basis(X_train, X_test, gamma)\n",
    "# class_number = np.sum(y_train_bin[I, np.newaxis] *  alpha[I, np.newaxis] * K_test[I, :], axis=0) - b * np.ones(shape=(n_test))\n",
    "# y_pred_bin = np.where(class_number > 0, 1, -1)\n",
    "# np.sum(y_pred_bin == y_test_bin) / n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM_binary():\n",
    "    def __init__(self, C, gamma):\n",
    "        self.C = C\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        n_train = X_train.shape[0]\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        K_train = radial_basis(X_train, X_train, self.gamma)\n",
    "        M = matrix(np.outer(y_train, y_train) * K_train)\n",
    "        e = matrix(np.ones(shape=(n_train, 1), dtype=float))\n",
    "        G = matrix(np.identity(n=n_train, dtype=float))\n",
    "        h = matrix(C * e)\n",
    "        A = matrix(y_train.reshape(1, -1).astype(float))\n",
    "        b = matrix(0.0)\n",
    "        self.sol = solvers.qp(M, e, G, h, A, b)\n",
    "        self.alpha = np.array(self.sol[\"x\"]).flatten()\n",
    "        self.I = np.argwhere(self.alpha > 0).flatten()\n",
    "        alpha_b_idx = np.argwhere((0 < self.alpha) & (self.alpha < C)).flatten()[0]\n",
    "        self.b = np.sum(\n",
    "            y_train[self.I] *  self.alpha[self.I] * K_train[self.I, alpha_b_idx]\n",
    "        )\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        n_test = X_test.shape[0]\n",
    "        K_test = radial_basis(self.X_train, X_test, self.gamma)\n",
    "        class_number = (\n",
    "            np.sum(\n",
    "                self.y_train[self.I, np.newaxis]\n",
    "                * self.alpha[self.I, np.newaxis]\n",
    "                * K_test[self.I, :],\n",
    "                axis=0\n",
    "            )\n",
    "            - self.b * np.ones(shape=(n_test))\n",
    "        )\n",
    "        y_pred = np.where(class_number > 0, 1, -1)\n",
    "        return y_pred\n",
    "\n",
    "    def accuracy(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        return np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.581"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = 0.03\n",
    "C = 100\n",
    "svm_36 = SVM_binary(C=C, gamma=gamma)\n",
    "svm_36.train(X_train, y_train_bin)\n",
    "svm_36.accuracy(X_test, y_test_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
