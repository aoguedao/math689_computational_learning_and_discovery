{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import secrets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from cvxopt import matrix\n",
    "from cvxopt import solvers\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "solvers.options['show_progress'] = False\n",
    "sns.set_context(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path().resolve().parent / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "# secrets.randbits(128) # 208905213533139122735706682150229709525\n",
    "rng = np.random.default_rng(208905213533139122735706682150229709525)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_path, labels, n_train_label, n_test_label, rng):\n",
    "    \"\"\"\n",
    "    Returns train and test data for some labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data_path: pathlib.PosixPath\n",
    "        Path of datasets\n",
    "\n",
    "    labels: list\n",
    "        Digits from MNIST set\n",
    "\n",
    "    n_train_label: int\n",
    "        Number of train samples for each label\n",
    "\n",
    "    n_test_label: int\n",
    "        Number of test samples for each label\n",
    "\n",
    "    rng: numpy.random._generator.Generator\n",
    "        Seed for reproducibility\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of np.array\n",
    "        X_train, y_train, X_test, y_test\n",
    "\n",
    "    \"\"\"\n",
    "    train_list = []  # Auxiliary list of train datasets\n",
    "    for f_train in data_path.glob(\"train*.txt\"):\n",
    "        if f_train.stem.removeprefix(\"train\") not in map(str, labels):\n",
    "            continue\n",
    "        raw_train = np.loadtxt(f_train)\n",
    "        if n_train_label is not None:\n",
    "            indices_train = rng.choice(raw_train.shape[0], n_train_label, replace=False)\n",
    "            raw_train = raw_train[indices_train, :]\n",
    "        target_train = raw_train[:, [0]]  # Target values, i.e. digit\n",
    "        features_train = raw_train[:, 1:] / 255\n",
    "        train_list.append(np.hstack((target_train, features_train)))\n",
    "    train_data = np.vstack(train_list)  # Concatenate train datasets\n",
    "\n",
    "    test_list = []\n",
    "    for f_test in data_path.glob(\"test*.txt\"):\n",
    "        if f_test.stem.removeprefix(\"test\") not in map(str, labels):\n",
    "            continue\n",
    "        raw_test = np.loadtxt(f_test)\n",
    "        if n_test_label is not None:\n",
    "            indices_test = rng.choice(raw_test.shape[0], n_test_label, replace=False)\n",
    "            raw_test = raw_test[indices_test, :]\n",
    "        target_test = raw_test[:, [0]]\n",
    "        features_test = raw_test[:, 1:] / 255\n",
    "        test_list.append(np.hstack((target_test, features_test)))\n",
    "    test_data = np.vstack(test_list)\n",
    "    X_train = train_data[:, 1:]\n",
    "    y_train = train_data[:, 0].astype(int)\n",
    "    X_test = test_data[:, 1:]\n",
    "    y_test = test_data[:, 0].astype(int)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radial_basis(X1, X2, gamma):\n",
    "    K = np.exp(-gamma * euclidean_distances(X1, X2, squared=True))\n",
    "    return K\n",
    "\n",
    "\n",
    "class SVM_binary():\n",
    "    def __init__(self, C, gamma):\n",
    "        self.C = C\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        n_train = X_train.shape[0]\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        K_train = radial_basis(X_train, X_train, self.gamma)\n",
    "        M = matrix(np.outer(y_train, y_train) * K_train)\n",
    "        e = matrix(np.ones(shape=(n_train, 1), dtype=float))\n",
    "        G = matrix(np.identity(n=n_train, dtype=float))\n",
    "        h = matrix(self.C * e)\n",
    "        A = matrix(y_train.reshape(1, -1).astype(float))\n",
    "        b = matrix(0.0)\n",
    "        self.sol = solvers.qp(M, e, G, h, A, b)\n",
    "        self.alpha = np.array(self.sol[\"x\"]).flatten()\n",
    "        self.I = np.argwhere(self.alpha > 0).flatten()\n",
    "        alpha_b_idx = self.alpha[(0 < self.alpha) & (self.alpha < self.C)].argmax()\n",
    "        self.b = np.sum(\n",
    "            y_train[self.I] *  self.alpha[self.I] * K_train[self.I, alpha_b_idx]\n",
    "        )\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        n_test = X_test.shape[0]\n",
    "        K_test = radial_basis(self.X_train, X_test, self.gamma)\n",
    "        class_number = (\n",
    "            np.sum(\n",
    "                self.y_train[self.I, np.newaxis]\n",
    "                * self.alpha[self.I, np.newaxis]\n",
    "                * K_test[self.I, :],\n",
    "                axis=0\n",
    "            )\n",
    "            - self.b * np.ones(shape=(n_test))\n",
    "        )\n",
    "        y_pred = np.where(class_number > 0, 1, -1)\n",
    "        return y_pred\n",
    "\n",
    "    def accuracy(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        return np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.03\n",
    "C = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Classification 3 vs 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([3, 6])\n",
    "n_train_label = 500\n",
    "n_test_label = 500\n",
    "X_train_36, y_train_36, X_test_36, y_test_36 = get_data(\n",
    "    data_path,\n",
    "    labels,\n",
    "    n_train_label,\n",
    "    n_test_label,\n",
    "    rng\n",
    ")\n",
    "min_label = np.min(labels)\n",
    "y_train_bin_36 = np.where(y_train_36 == min_label, -1, 1)  # y_i \\in {-1, 1}\n",
    "y_test_bin_36 = np.where(y_test_36 == min_label, -1, 1)  # y_i \\in {-1, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_36 = SVM_binary(C=C, gamma=gamma)\n",
    "svm_36.train(X_train_36, y_train_bin_36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Accuracy 3 vs 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.846"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_36.accuracy(X_test_36, y_test_bin_36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Reduction of training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = [0.75, 0.90, 0.95]\n",
    "n_train = X_train_36.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_36_dict = {}\n",
    "y_train_36_dict = {}\n",
    "for factor in factors:\n",
    "    n_per_label = int((n_train - n_train * factor) / len(labels))\n",
    "    X_train_tmp_list = []\n",
    "    y_train_tmp_list = []\n",
    "    for label in labels:\n",
    "        mask_train = y_train_36 == label\n",
    "        y_train_tmp = y_train_36[mask_train]\n",
    "        X_train_tmp = X_train_36[mask_train, :]\n",
    "        idx = rng.choice(y_train_tmp.shape[0], n_per_label, replace=False)\n",
    "        X_train_tmp_list.append(X_train_tmp[idx, :])\n",
    "        y_train_tmp_list.append(y_train_tmp[idx])\n",
    "    X_train_36_dict[factor] = np.vstack(X_train_tmp_list)\n",
    "    y_train_36_dict[factor] = np.concatenate(y_train_tmp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 has 250 samples.\n",
      "0.9 has 100 samples.\n",
      "0.95 has 50 samples.\n"
     ]
    }
   ],
   "source": [
    "for factor, X in X_train_36_dict.items():\n",
    "    print(f\"{factor} has {X.shape[0]} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/Documents/git/math689_computational_learning_and_discovery/assignments/final.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Documents/git/math689_computational_learning_and_discovery/assignments/final.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m y_test_bin \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(y_test_36 \u001b[39m==\u001b[39m min_label, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Documents/git/math689_computational_learning_and_discovery/assignments/final.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m svm \u001b[39m=\u001b[39m SVM_binary(C\u001b[39m=\u001b[39mC, gamma\u001b[39m=\u001b[39mgamma)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Documents/git/math689_computational_learning_and_discovery/assignments/final.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m svm\u001b[39m.\u001b[39;49mtrain(X_train, y_train_bin)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Documents/git/math689_computational_learning_and_discovery/assignments/final.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m pred_36[factor] \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39mpredict(X_test_36)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Documents/git/math689_computational_learning_and_discovery/assignments/final.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m test_accuracy_36[factor] \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39maccuracy(X_test_36, y_test_bin)\n",
      "\u001b[1;32m/mnt/d/Documents/git/math689_computational_learning_and_discovery/assignments/final.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Documents/git/math689_computational_learning_and_discovery/assignments/final.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msol[\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Documents/git/math689_computational_learning_and_discovery/assignments/final.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mI \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margwhere(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Documents/git/math689_computational_learning_and_discovery/assignments/final.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m alpha_b_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha[(\u001b[39m0\u001b[39;49m \u001b[39m<\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha) \u001b[39m&\u001b[39;49m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha \u001b[39m<\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC)]\u001b[39m.\u001b[39;49margmax()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Documents/git/math689_computational_learning_and_discovery/assignments/final.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Documents/git/math689_computational_learning_and_discovery/assignments/final.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     y_train[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mI] \u001b[39m*\u001b[39m  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mI] \u001b[39m*\u001b[39m K_train[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mI, alpha_b_idx]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Documents/git/math689_computational_learning_and_discovery/assignments/final.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "pred_36 = {}\n",
    "test_accuracy_36 = {}\n",
    "for factor in factors:\n",
    "    X_train = X_train_36_dict[factor]\n",
    "    y_train = y_train_36_dict[factor]\n",
    "    min_label = np.min(labels)\n",
    "    y_train_bin = np.where(y_train == min_label, -1, 1)\n",
    "    y_test_bin = np.where(y_test_36 == min_label, -1, 1)\n",
    "    svm = SVM_binary(C=C, gamma=gamma)\n",
    "    svm.train(X_train, y_train_bin)\n",
    "    pred_36[factor] = svm.predict(X_test_36)\n",
    "    test_accuracy_36[factor] = svm.accuracy(X_test_36, y_test_bin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.75: 0.961, 0.9: 0.682}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy_36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Reduction of pixeles uniformly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train_36.shape[1]\n",
    "X_train_36_pixel_red_dict = {}\n",
    "X_test_36_pixel_red_dict = {}\n",
    "for factor in factors:\n",
    "    n_features_new = int(n_features * (1 - factor))\n",
    "    idx = np.linspace(0, n_features, num=n_features_new, endpoint=False, dtype=int)\n",
    "    X_train_36_pixel_red_dict[factor] = X_train_36[:, idx]\n",
    "    X_test_36_pixel_red_dict[factor] = X_test_36[:, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pixel_36 = {}\n",
    "test_accuracy_pixel_36 = {}\n",
    "for factor in factors:\n",
    "    X_train = X_train_36_pixel_red_dict[factor]\n",
    "    X_test = X_test_36_pixel_red_dict[factor]\n",
    "    svm = SVM_binary(C=C, gamma=gamma)\n",
    "    svm.train(X_train, y_train_bin_36)\n",
    "    pred_pixel_36[factor] = svm.predict(X_test)\n",
    "    test_accuracy_pixel_36[factor] = svm.accuracy(X_test, y_test_bin_36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.75: 0.885, 0.9: 0.854, 0.95: 0.651}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy_pixel_36"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
