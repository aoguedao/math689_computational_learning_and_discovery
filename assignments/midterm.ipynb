{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import secrets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path().resolve().parent / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "# secrets.randbits(128) # 208905213533139122735706682150229709525\n",
    "rng = np.random.default_rng(208905213533139122735706682150229709525)\n",
    "indices_train = rng.choice(5000, 2500, replace=False)\n",
    "indices_test = rng.choice(800, 400, replace=False)\n",
    "flag_full_dataset = False  # If it is True it will use full train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 785)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list = []  # Auxiliary list of train datasets\n",
    "for f in data_path.glob(\"train*.txt\"):\n",
    "    # Sample or full dataset\n",
    "    raw_data = np.loadtxt(f) if flag_full_dataset else np.loadtxt(f)[indices_train, :]\n",
    "    target = raw_data[:, [0]]  # Target values, i.e. digit\n",
    "    features = raw_data[:, 1:] / raw_data[:, 1:].max(axis=1, keepdims=True)\n",
    "    train_list.append(np.hstack((target, features)))  # Add to the temp list\n",
    "train_data = np.vstack(train_list)  # Concatenate train datasets\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 785)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similar to train dataset\n",
    "test_list = []\n",
    "for f in data_path.glob(\"test*.txt\"):\n",
    "    raw_data = np.loadtxt(f) if flag_full_dataset else np.loadtxt(f)[indices_test, :]\n",
    "    target = raw_data[:, [0]]\n",
    "    features = raw_data[:, 1:] / raw_data[:, 1:].max(axis=1, keepdims=True)\n",
    "    test_list.append(np.hstack((target, features)))\n",
    "test_data = np.vstack(test_list)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split datasets into features matrices and target vectors\n",
    "rng.shuffle(train_data)\n",
    "X_train = train_data[:, 1:]\n",
    "y_train = train_data[:, 0].astype(int)\n",
    "X_test = test_data[:, 1:]\n",
    "y_test = test_data[:, 0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feature = X_train.shape[1]\n",
    "n_output = np.unique(y_train).size  # Unique number of digits/classes\n",
    "n_hidden = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "x = X_train[0:1, :].T\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_1 = np.random.uniform(-0.5, 0.5, size=(n_output, n_feature))\n",
    "W_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_1 = np.random.uniform(-0.5, 0.5, size=(n_output, 1))\n",
    "bias_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (404827623.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [11], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    hidden1 =\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "hidden1 = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
